<h1>pbsmon</h1>
<p>pbsmon is a command-line utility, python module and monitoring daemon for the PBS cluster.</p>
<p>[toc]</p>
<h2>installation</h2>
<p>git clone</p>
<pre><code>power8$ git clone https://gitlab.com/tomerdmnt/pbsmon</code></pre>
<p>install on the head node. use the <strong>--user flag</strong> to install locally without root permissions</p>
<pre><code>power8$ cd pbsmon &amp;&amp; python setup.py install --user</code></pre>
<p>if <strong>--user flag</strong> was used add bin directory to $PATH variable</p>
<pre><code>power8$ export PATH=$PATH:~/.local/bin/</code></pre>
<h3>installation one-liner</h3>
<pre><code>git clone https://gitlab.com/tomerdmnt/pbsmon &amp;&amp; cd pbsmon &amp;&amp; python setup.py install --user &amp;&amp; echo &quot;export PATH=\$PATH:~/.local/bin/&quot; &gt;&gt; ~/.bashrc &amp;&amp; . ~/.bashrc</code></pre>
<h3>RPM</h3>
<p>prepare an rpm (centos package) using the following command from the top of the pbsmon directory tree</p>
<pre><code>python2 setup.py bdist_rpm</code></pre>
<h2>command-line usage</h2>
<p>pbsmon is a collection of sub commands. You can view a help message corresponding to each subcommand by adding an -h flag, for example:</p>
<pre><code>$ pbsmon cpuutil -h
usage: pbsmon cpuutil [-h] [-u] [cluster]
...</code></pre>
<p>or the general help message</p>
<pre><code>$ pbsmon -h
usage: pbsmon [-h]

              {ls,queues,cpuutil,memutil,walltime0,cputime,runtime-outliers,memabuse,monitor,web,checknfs}
              ...

commands:
  {ls,queues,cpuutil,memutil,walltime0,cputime,runtime-outliers,memabuse,monitor,web,checknfs}
    ls                  List clusters and nodes in cluster
    queues              List queues in cluster
    cpuutil             Display cluster&#39;s CPU utilization
    memutil             Display cluster&#39;s Memory utilization
    walltime0           List running jobs with walltime 0
    cputime             List running jobs low cputime
    runtime-outliers    List jobs with unlikely runtime
    memabuse            List servers with memory abuse
    monitor             monitor simulation
    web                 web monitor
    checknfs            check an nfs mount is up

flags:
  -h, --help            show this help message and exit</code></pre>
<h3>pbsmon ls</h3>
<p>List all the different qlist clusters (i.e. tamir-short, tamir-nano4, ...)</p>
<pre><code>$ pbsmon ls
tamir-short
tamir-nano4
...</code></pre>
<p>List all nodes (server names) belonging to a cluster</p>
<pre><code>$ pbsmon ls tamir-short
compute-0-46
compute-0-45
...</code></pre>
<h3>pbsmon queues</h3>
<p>List all queues pointing to a cluster</p>
<pre><code>$ pbsmon queues nano
nano3
nano2
nano1
nano5
nano4</code></pre>
<h3>pbsmon cpuutil</h3>
<p>Display CPU utilization info for all nodes in cluster</p>
<pre><code>$ pbsmon cpuutil tamir-nano4
...
compute-0-232                23/24         free                
compute-0-233                24/24         job-busy            
compute-0-234                 0/24         down,offline        
compute-0-235                 0/24         offline             
-----------------------------
total:                      860/932</code></pre>
<p>Display CPUUtilization per user for all nodes in cluster</p>
<pre><code>$ pbsmon cpuutil -u tamir-nano4
...
giladshaham                  52
dalon                         1
zurhadas2                   780
wengenouyang                  8
...</code></pre>
<h3>pbsmon memutil</h3>
<p>Display memory utilization info for all nodes in cluster:</p>
<pre><code>$ pbsmon memutil tamir-nano4
...
ompute-0-233              70gb/94gb                   job-busy
compute-0-234               0kb/94gb               down,offline
compute-0-235               0kb/94gb                    offline
-----------------------------
total:                   2619gb/4482gb</code></pre>
<p>Display CPUUtilization per user for all nodes in cluster</p>
<pre><code>$ pbsmon memutil -u tamir-nano4
...
giladshaham               124gb/253gb
dalon                     269mb/3gb
zurhadas2                 269gb/2313gb
wengenouyang              210mb/23gb
...</code></pre>
<h3>pbsmon runtime-outliers</h3>
<p>The runtime-outliers command will run indefinitely and monitor jobs that ended. Each job&#39;s wall-time will be compared to other job&#39;s wall-time with the same executable name. It outputs job IDs of jobs that ended too soon, or ran for an unusual period of time. It uses the following calculation to determine weather a job is an outlier:
$$
Q1 = walltime\ 25th\ percentile\
Q3 = walltime\ 75th\ percentile\
IQR = Q3 - Q1\
if\ walltime(job) &gt; Q3 + k<em>IQR \or\ walltime(job) &lt; Q1 - k</em>IQR
$$</p>
<p>You can determine the constant $k$ with the -k flag (default 1.5), and monitor only after certain user&#39;s job using -u [user] flag.</p>
<pre><code>$ pbsmon runtime-outliers -k=2 tamir-nano4
...</code></pre>
<h3>pbsmon monitor</h3>
<p>Monitoring simulation, where the alerts and recepients are written to stdout, and no emails are sent.</p>
<pre><code>$ pbsmon monitor tamir-nano4</code></pre>
<h3>pbsmon cputime</h3>
<p>List running jobs low cputime, i.e. find jobs with a ratio between walltime and cputime lower than k.
k defaults to .5</p>
<pre><code>$ pbsmon cputime -k .2
4231056.power8.tau.ac.il              02:05:27 / 908:09:22       zurhadas2 
4374513.power8.tau.ac.il              05:27:45 / 496:23:16       mich1     
4580742.power8.tau.ac.il              04:14:27 / 185:15:01       mich1     
4912946.power8.tau.ac.il              00:01:04 / 00:38:50        renanaco  
4229855.power8.tau.ac.il              01:57:57 / 953:43:57       zurhadas2 
4345069.power8.tau.ac.il              01:04:29 / 528:58:27       zurhadas2 
4384536.power8.tau.ac.il              00:00:07 / 435:11:40       okushnir  
4384634.power8.tau.ac.il              01:06:27 / 431:29:52       okushnir  
4415841.power8.tau.ac.il              09:24:48 / 382:05:39       zoharzaf  
4417436.power8.tau.ac.il              02:40:16 / 360:28:58       shimshi   
4569304.power8.tau.ac.il              02:53:31 / 241:28:10       zoharzaf  
4595657.power8.tau.ac.il              00:07:02 / 164:37:34       zurhadas2</code></pre>
<h3>pbsmon memabuse</h3>
<p>List servers with memory abuse. memory abuse occurs when jobs on a certain node takes enough memory so that
the server won&#39;t be able to run jobs on all of its cpus during a load, because the memory will become the
limiting factor</p>
<pre><code>$ pbsmon memabuse
compute-0-80        5 jobs   251.9gb/252.4gb    talimc,renanaco
compute-0-211       23 jobs    61.5gb/62.3gb     zurhadas2,xpxu2010,mich1,renanaco
compute-0-214       1 jobs   248.0gb/248.0gb    talimc</code></pre>
<h3>pbsmon checknfs</h3>
<p>check an nfs mount is up.</p>
<pre><code>$pbsmon checknfs /tamir
/tamir is down
$ pbsmon checknfs /tamir1
/tamir1 is up</code></pre>
<h3>pbsmon web</h3>
<p>Starts the web monitoring application.</p>
<p>If no port is included, a port is chosen by the system</p>
<pre><code>$ pbsmon web tamir-nano4</code></pre>
<p>However you can choose a specific port</p>
<pre><code>$ pbsmon web -p 39063 tamir-nano4</code></pre>
<p>The apache server maps /tamir on power8 server to port 39063 using these lines in /etc/httpd/conf/httpd.conf:</p>
<pre><code>ProxyPassMatch    ^/tamir http://power8.tau.ac.il:39063/
ProxyPassReverse  ^/tamir http://power8.tau.ac.il:39063/</code></pre>
<p>To start the server and disconnect it from the current ssh session, i.e. we use the nohup unix utility:</p>
<pre><code>nohup pbsmon web -p 39063 tamir-nano4 &amp;</code></pre>
<p>So if the server is down, this command should be ran.</p>
<h2>monitoring daemon (alerts)</h2>
<p>The monitoring daemon runs indefinitely and monitors for the system&#39;s health. the alerts can be viewed in the web monitoring page under alerts.</p>
<h3>Types of alerts</h3>
<h4>memabuse</h4>
<p>Only while there are queued jobs waiting to be run, issues a warning for each user on each node that has unused cores, but not enough
memory to run another job</p>
<pre><code>memory abuse (unused cores) on node &lt;hostname&gt;, memory usage: &lt;memory used&gt;/&lt;memory available&gt;, average job memory: &lt;avg job mem&gt;</code></pre>
<h4>low cputime</h4>
<p>Warning for each job when its cputime is less than half of its walltime</p>
<pre><code>job &lt;job id&gt; has low cputime &lt;cputime&gt; / &lt;walltime&gt;</code></pre>
<h4>nfs</h4>
<p>Checks /tamir1 is mounted on power8</p>
<pre><code>/tamir1 is stale or unmounted</code></pre>
<h4>nano + tamir-short = tamir-nano4</h4>
<pre><code>&lt;node name&gt; in tamir-nano4 and not in nano or tamir-short
&lt;node name&gt; in nano4 and not in tamir-nano4
&lt;node name&gt; in tamir-short and not in tamir-nano4</code></pre>
<h2>python module usage</h2>
<p>As a module pbsmon imports the methods: getjobs(), getnodes(), getqueues() and getclusters().</p>
<p>Each one of these returns a list of object of type Resource, which are dictionaries with the followin methods:</p>
<pre><code class="lang-python">&gt;&gt;&gt; resource.get(&#39;field_name&#39;) # returns the value of the field with key &#39;field_name&#39;
&gt;&gt;&gt; resource.get(&#39;field_name&#39;, &#39;default&#39;) # returns the value of the field with field_name if it exists, otherwise return &#39;default&#39;
&gt;&gt;&gt; resource.find(&#39;time&#39;) # returns a dictionary of all key value pairs where key is of *time*</code></pre>
<p>Values are parsed according to their type, for example:</p>
<pre><code class="lang-python">&gt;&gt;&gt; job.get(&#39;resources_used.walltime&#39;).total_seconds() # time intervals are parsed as time.timedelta types
684397.0
&gt;&gt;&gt; job.get(&#39;resources_used.mem&#39;).nodes[0].get(&#39;resources_assigned.mem&#39;).bytes() # use .bytes() to get #bytes in a memory field
37748736000</code></pre>
<h3>getjobs()</h3>
<p>Gets all jobs which are currently running, or might run on the specified cluster. If the cluster argument is omitted, the function will return all jobs on the server.</p>
<pre><code class="lang-python">&gt;&gt;&gt; from pbsmon import getjobs
&gt;&gt;&gt; 
&gt;&gt;&gt; jobs = getjobs(&#39;tamir-nano4&#39;)
&gt;&gt;&gt; running_jobs = [j for j in jobs if j.get(&#39;job_state&#39;,&#39;Q&#39;) == &#39;R&#39;] # filter for running jobs
&gt;&gt;&gt; 
&gt;&gt;&gt; running_jobs[0].get(&#39;resources_used.walltime&#39;).total_seconds() # get walltime in seconds
684397.0</code></pre>
<h3>getnodes()</h3>
<p>Get all nodes which mapped through Qlist to the specified cluster.</p>
<pre><code class="lang-python">&gt;&gt;&gt; from pbsmon import getnodes
&gt;&gt;&gt; 
&gt;&gt;&gt; nodes = getnodes(&#39;tamir-nano4&#39;)
&gt;&gt;&gt; nodes[0].get(&#39;resources_assigned.ncpus&#39;) # nodes currently used CPUs
12</code></pre>
<h3>getqueues()</h3>
<pre><code class="lang-python">&gt;&gt;&gt; from pbsmon import getqueues
&gt;&gt;&gt;
&gt;&gt;&gt; getqueues(&#39;tamir-nano4&#39;)
...</code></pre>

